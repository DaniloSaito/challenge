{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87596d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, TimestampType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType\n",
    "from pyspark.sql.functions import col,array_contains, regexp_replace, split, to_timestamp\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fea66c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+---------------+----------------+----------------+-----------------+-------------------+\n",
      "| region|         datasource|origin_latitude|origin_longitude|destiny_latitude|destiny_longitude|      trip_datetime|\n",
      "+-------+-------------------+---------------+----------------+----------------+-----------------+-------------------+\n",
      "| Prague|          funny_car|      14.497379|        50.00137|       14.431095|         50.04053|2018-05-28 09:03:00|\n",
      "|  Turin|           baba_car|      7.6728377|       44.995712|        7.720369|        45.067825|2018-05-21 02:54:00|\n",
      "| Prague|       cheap_mobile|      14.324273|        50.00002|       14.477679|          50.0934|2018-05-13 08:52:00|\n",
      "|  Turin|bad_diesel_vehicles|       7.541509|       45.091606|       7.7452865|        45.026287|2018-05-06 09:49:00|\n",
      "|  Turin|      pt_search_app|       7.614078|        45.13433|       7.5274973|         45.03335|2018-05-23 12:45:00|\n",
      "|Hamburg|bad_diesel_vehicles|       10.07299|        53.62045|        9.789198|        53.463158|2018-05-15 09:13:00|\n",
      "|Hamburg|          funny_car|       9.910278|       53.583862|       10.025579|         53.41207|2018-05-13 13:09:00|\n",
      "|  Turin|       cheap_mobile|      7.5607853|       45.019016|       7.5835686|         45.10527|2018-05-06 00:00:00|\n",
      "|  Turin|       cheap_mobile|       7.702418|        45.05755|       7.6232295|          44.9997|2018-05-14 02:07:00|\n",
      "|Hamburg|       cheap_mobile|      10.052601|       53.534977|       10.058896|        53.494865|2018-05-04 00:46:00|\n",
      "+-------+-------------------+---------------+----------------+----------------+-----------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"trips.csv\", sep=';', header=True)\n",
    "\n",
    "from pyspark.sql.functions import col,array_contains, regexp_replace, split, to_timestamp\n",
    "\n",
    "df_treated =  df.withColumn(\"clean_origin\", regexp_replace(\"origin_coord\",\"POINT |\\(|\\)\",\"\")) \\\n",
    "                .withColumn(\"clean_destiny\", regexp_replace(\"destination_coord\",\"POINT |\\(|\\)\",\"\"))\n",
    "\n",
    "df2 = df_treated.withColumn('origin_latitude', split(df_treated['clean_origin'], ' ').getItem(0).cast(\"float\")) \\\n",
    "                .withColumn('origin_longitude', split(df_treated['clean_origin'], ' ').getItem(1).cast(\"float\")) \\\n",
    "                .withColumn('destiny_latitude', split(df_treated['clean_destiny'], ' ').getItem(0).cast(\"float\")) \\\n",
    "                .withColumn('destiny_longitude', split(df_treated['clean_destiny'], ' ').getItem(1).cast(\"float\"))\n",
    "\n",
    "df2 = df2.withColumn(\"trip_datetime\", to_timestamp(\"datetime\", \"dd/MM/yyyy HH:mm\"))\n",
    "\n",
    "df2 = df2.drop('origin_coord', 'destination_coord','datetime','clean_origin','clean_destiny')\n",
    "\n",
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "309fab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set variable to be used to connect the database\n",
    "database = \"Jobsity\"\n",
    "table = \"dbo.Trips\"\n",
    "\n",
    "#write the dataframe into a sql table\n",
    "df2.write.mode(\"overwrite\") \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", f\"jdbc:sqlserver://localhost:1433;databaseName={database};integratedSecurity=true\") \\\n",
    "    .option(\"dbtable\", table) \\\n",
    "    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34d7667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
