{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87596d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, TimestampType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType\n",
    "from pyspark.sql.functions import col,array_contains, regexp_replace, split, to_timestamp, round, when, hour, count\n",
    "\n",
    "# spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a135c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "spark = SparkSession.builder.appName(\"Test2\") \\\n",
    "      .config(\"spark.dynamicAllocation.maxExecutors\", \"4\") \\\n",
    "      .config(\"spark.executor.cores\", \"4\") \\\n",
    "      .config(\"spark.executor.memory\", \"512m\") \\\n",
    "      .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "      .config(\"spark.dynamicAllocation.initialExecutors\", \"4\") \\\n",
    "      .config(\"spark.executor.instances\", \"4\") \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "381e6c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "93\n",
      "+-------+---------------+----------------+----------------+-----------------+-------------+---------------+\n",
      "| region|origin_latitude|origin_longitude|destiny_latitude|destiny_longitude|period_of_day|number_of_trips|\n",
      "+-------+---------------+----------------+----------------+-----------------+-------------+---------------+\n",
      "|  Turin|           45.1|             7.6|            45.1|              7.6|         Dawn|              2|\n",
      "| Prague|           50.1|            14.3|            50.1|             14.5|        Night|              1|\n",
      "| Prague|           50.0|            14.6|            50.1|             14.3|        Night|              1|\n",
      "|  Turin|           45.1|             7.5|            45.0|              7.6|      Morning|              1|\n",
      "|Hamburg|           53.5|             9.9|            53.5|             10.0|         Dawn|              1|\n",
      "| Prague|           50.1|            14.4|            50.0|             14.4|         Dawn|              1|\n",
      "|  Turin|           45.0|             7.6|            45.1|              7.7|      Morning|              1|\n",
      "|Hamburg|           53.6|            10.1|            53.6|              9.9|        Night|              1|\n",
      "| Prague|           50.1|            14.5|            50.1|             14.7|         Dawn|              1|\n",
      "|  Turin|           45.1|             7.6|            45.1|              7.6|      Morning|              1|\n",
      "|  Turin|           45.1|             7.7|            45.0|              7.5|         Dawn|              1|\n",
      "|  Turin|           45.0|             7.6|            45.0|              7.8|    Afternoon|              1|\n",
      "|  Turin|           45.0|             7.6|            45.1|              7.6|    Afternoon|              1|\n",
      "| Prague|           50.0|            14.5|            50.1|             14.7|         Dawn|              1|\n",
      "|  Turin|           45.0|             7.6|            45.0|              7.8|      Morning|              1|\n",
      "|Hamburg|           53.5|            10.1|            53.5|             10.1|         Dawn|              1|\n",
      "|Hamburg|           53.4|            10.0|            53.4|             10.1|      Morning|              1|\n",
      "|  Turin|           45.1|             7.5|            45.0|              7.7|      Morning|              1|\n",
      "| Prague|           50.1|            14.4|            50.1|             14.3|    Afternoon|              1|\n",
      "|  Turin|           45.0|             7.6|            45.1|              7.6|         Dawn|              1|\n",
      "+-------+---------------+----------------+----------------+-----------------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spark.read.csv(r'C:\\Users\\Visagio\\Desktop\\Jobsity challenge\\trips.csv', sep=';', header=True)\n",
    "\n",
    "# parsing latitude and longitude\n",
    "df_coord =  df.withColumn(\"clean_origin\", regexp_replace(\"origin_coord\",\"POINT |\\(|\\)\",\"\")) \\\n",
    "                .withColumn(\"clean_destiny\", regexp_replace(\"destination_coord\",\"POINT |\\(|\\)\",\"\"))\n",
    "\n",
    "df_coord2 = df_coord.withColumn('origin_latitude', split(df_coord['clean_origin'], ' ').getItem(1).cast(\"float\")) \\\n",
    "                .withColumn('origin_longitude', split(df_coord['clean_origin'], ' ').getItem(0).cast(\"float\")) \\\n",
    "                .withColumn('destiny_latitude', split(df_coord['clean_destiny'], ' ').getItem(1).cast(\"float\")) \\\n",
    "                .withColumn('destiny_longitude', split(df_coord['clean_destiny'], ' ').getItem(0).cast(\"float\"))\n",
    "\n",
    "# similar origins and destiny has to be grouped together, so we are rounding with 1 decimal place\n",
    "df_coord3 = df_coord2.withColumn(\"origin_latitude\", round(col('origin_latitude'),1)) \\\n",
    "                     .withColumn(\"origin_longitude\", round(col('origin_longitude'),1)) \\\n",
    "                     .withColumn(\"destiny_latitude\", round(col('destiny_latitude'),1)) \\\n",
    "                     .withColumn(\"destiny_longitude\", round(col('destiny_longitude'),1))\n",
    "\n",
    "# defining period of the day to group similar trips together\n",
    "df_time1 = df_coord3.withColumn(\"trip_datetime\", to_timestamp(\"datetime\", \"dd/MM/yyyy HH:mm\"))\n",
    "\n",
    "df_time2 = df_time1.withColumn(\"period_of_day\", when(hour(col(\"trip_datetime\")) <= 5, \"Dawn\")\n",
    "                                     .when(hour(col(\"trip_datetime\")) <= 11, \"Morning\")\n",
    "                                     .when(hour(col(\"trip_datetime\")) <= 17, \"Afternoon\")\n",
    "                                     .otherwise(\"Night\"))\n",
    "print(df_time2.count())\n",
    "df_grouped = df_time2.groupBy('region','origin_latitude', 'origin_longitude', \\\n",
    "                         'destiny_latitude', 'destiny_longitude', 'period_of_day').agg(count(\"*\").alias(\"number_of_trips\"))\n",
    "\n",
    "print(df_grouped.count())\n",
    "df_grouped.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfb6cf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3885713\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#test scalability\n",
    "\n",
    "df = spark.read.csv(\"test.csv\", sep=';', header=True)\n",
    "df_treated =  df.withColumn(\"clean_origin\", regexp_replace(\"origin_coord\",\"POINT |\\(|\\)\",\"\")) \\\n",
    "                .withColumn(\"clean_destiny\", regexp_replace(\"destination_coord\",\"POINT |\\(|\\)\",\"\"))\n",
    "\n",
    "df2 = df_treated.withColumn('origin_latitude', split(df_treated['clean_origin'], ' ').getItem(1).cast(\"float\")) \\\n",
    "                .withColumn('origin_longitude', split(df_treated['clean_origin'], ' ').getItem(0).cast(\"float\")) \\\n",
    "                .withColumn('destiny_latitude', split(df_treated['clean_destiny'], ' ').getItem(1).cast(\"float\")) \\\n",
    "                .withColumn('destiny_longitude', split(df_treated['clean_destiny'], ' ').getItem(0).cast(\"float\"))\n",
    "\n",
    "df2 = df2.withColumn(\"trip_datetime\", to_timestamp(\"datetime\", \"dd/MM/yyyy HH:mm\"))\n",
    "\n",
    "df2 = df2.drop('origin_coord', 'destination_coord','datetime','clean_origin','clean_destiny')\n",
    "\n",
    "df3 = df2.withColumn(\"origin_latitude_rounded\", round(col('origin_latitude')/0.1,0)) \\\n",
    ".withColumn(\"origin_longitude_rounded\", round(col('origin_longitude')/0.1,0)) \\\n",
    ".withColumn(\"destiny_latitude_rounded\", round(col('destiny_latitude')/0.1,0)) \\\n",
    ".withColumn(\"destiny_longitude_rounded\", round(col('destiny_longitude')/0.1,0))\n",
    "\n",
    "\n",
    "df4 = df3.alias('df4')\n",
    "df5 = df3.join(df4, df3.region == df4.region).select('df4.*')\n",
    "\n",
    "df6 = df5.alias('df6')\n",
    "df7 = df5.join(df6, df5.region == df6.region).select('df6.*')\n",
    "\n",
    "# df9 = df3.alias('df9')\n",
    "# df8 = df7.join(df9, df7.region == df9.region).select('df9.*')\n",
    "\n",
    "print(df7.count())\n",
    "df7.write.mode(\"overwrite\").parquet(\"C:/Users/Visagio/Desktop/Jobsity challenge/outputs/test.parquet\")\n",
    "# df7.write.mode(\"overwrite\").csv(\"C:/Users/Visagio/Desktop/Jobsity challenge/outputs/test.csv\")\n",
    "\n",
    "#set variable to be used to connect the database\n",
    "# database = \"Jobsity\"\n",
    "# table = \"dbo.Trips\"\n",
    "\n",
    "#write the dataframe into a sql table\n",
    "# df3.write.mode(\"overwrite\") \\\n",
    "#     .format(\"jdbc\") \\\n",
    "#     .option(\"url\", f\"jdbc:sqlserver://localhost:1433;databaseName={database};integratedSecurity=true\") \\\n",
    "#     .option(\"dbtable\", table) \\\n",
    "#     .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n",
    "#     .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6640a7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2022_10_16_18_11_56_172544\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# current date and time\n",
    "curDTObj = datetime.now()\n",
    "\n",
    "# current time\n",
    "timeStr = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "print(\"Time:\", timeStr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
